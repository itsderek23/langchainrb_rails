ðŸ’ŽðŸ”— Langchain.rb for Rails
---
The fastest way to sprinkle AI âœ¨ on top of your Rails app. Add OpenAI-powered question-and-answering in minutes.

![Tests status](https://github.com/andreibondarev/langchainrb_rails/actions/workflows/ci.yml/badge.svg?branch=main)
[![Gem Version](https://badge.fury.io/rb/langchainrb_rails.svg)](https://badge.fury.io/rb/langchainrb_rails)
[![Docs](http://img.shields.io/badge/yard-docs-blue.svg)](http://rubydoc.info/gems/langchainrb_rails)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/andreibondarev/langchainrb_rails/blob/main/LICENSE.txt)
[![](https://dcbadge.vercel.app/api/server/WDARp7J2n8?compact=true&style=flat)](https://discord.gg/WDARp7J2n8)

## Dependencies

* Ruby 3.0+
* Postgres 11+

## Table of Contents

- [Installation](#installation)
- [Generators](#rails-generators)

## Installation

Install the gem and add to the application's Gemfile by executing:

    bundle add langchainrb_rails

If bundler is not being used to manage dependencies, install the gem by executing:

    gem install langchainrb_rails

## Configuration w/PgVector (requires Postgres 11+)

1. Generate changes to support vectorsearch in your chosen ActiveRecord model

```bash
rails generate langchainrb_rails:pgvector --model=Product --llm=openai
```

This adds required dependencies to your Gemfile, creates the initializer file `config/initializers/langchainrb_rails.rb`, database migrations to support vectorsearch, and adds the necessary code to the ActiveRecord model to enable vectorsearch.

2. Bundle && Migrate

```bash
bundle install && rails db:migrate
```

3. Set the env var `OPENAI_API_KEY` to your OpenAI API key.

4. Generate embeddings for your model

```ruby
[YOUR MODEL].embed!
```

This can take a while depending on the number of database records.

## Usage

### Question and Answering

```ruby
Product.ask("list the brands of shoes that are in stock")
```

Returns a `String` with a natural language answer. The answer is assembled using the following steps:

1. Turn the `question` into an embedding using the selected LLM.
2. Find records that most closely match the question using Postgres vector similarity search (#similarity_search).
3. Create a prompt using the question and insert the records (via `#as_vector`) into the prompt as context.
4. Generate a completion using the prompt and the selected LLM.

### Similarity Search

```ruby
Product.similarity_search("t-shirt")
```

Returns ActiveRecord records that most closely match the `query` using Postgres vector similarity search.

## Customization

## Changing the vector representation of a record

By default, embeddings are generated by calling the following within your model:

```ruby
to_json(except: :embedding)
```

You can override this by defining an `#as_vector` method in your model:

```ruby
def as_vector
  res = to_json(except: :embedding, :owner_id, :user_id, :category_id)
  res.merge({ "owner" => owner.name, "user" => user.name, "category" => category.name })
end
```

Re-generate embeddings after modifying this method:

```ruby
[YOUR MODEL].embed!
```

## Rails Generators

### PgVector Generator

```bash
rails generate langchainrb_rails:pgvector --model=Product --llm=openai
```

### Pinecone Generator - adds vectorsearch to your ActiveRecord model
```bash
rails generate langchainrb_rails:pinecone --model=Product --llm=openai
```

Available `--llm` options: `cohere`, `google_palm`, `hugging_face`, `llama_cpp`, `ollama`, `openai`, and `replicate`. The selected LLM will be used to generate embeddings and completions.

The `--model` option is used to specify which ActiveRecord model vectorsearch capabilities will be added to.

Pinecone Generator does the following:
1. Creates the `config/initializers/langchainrb_rails.rb` initializer file
2. Adds necessary code to the ActiveRecord model to enable vectorsearch
3. Adds `pinecone` gem to the Gemfile

### Chroma Generator - adds vectorsearch to your ActiveRecord model
```bash
rails generate langchainrb_rails:chroma --model=Product --llm=openai
```
